---
title: "Module: Deepfakes and Synthetic Media"
slug: "Module-Deepfakes-Synthetic-Media"
author: "SAUFEX Consortium"
date: "2026-01-23"
description: "Understanding deepfakes, how they're created, detected, and their implications for truth and trust in society."
learningPath: "AI and Hybrid Threats"
moduleNumber: 2
estimatedTime: "8 minutes"
---

[![Logo](https://cdn.dorik.com/5ffdabc144afdb0011b83e1d/62474e909f34ad00115b4d4f/images/Saufex_09cgctgm.png)](https://saufex.eu/)

*   [Contact](mailto:info@saufex.eu)
*   [Join Discord](https://discord.gg/bvaGd5rahu)

# Module: Deepfakes and Synthetic Media

By **SAUFEX Consortium** | Last Updated: **23 January 2026**

[screen 1]

In 2022, a deepfake video showed Ukrainian President Zelenskyy telling his soldiers to surrender. It was crude and quickly debunked, but it demonstrated a frightening reality: anyone with a laptop can now put words in anyone else's mouth.

Welcome to the age of synthetic media.

[screen 2]

## What Are Deepfakes?

Deepfakes are synthetic media created using deep learning algorithms - specifically, neural networks that can generate or alter video, audio, and images to create highly realistic but entirely fabricated content.

The term combines "deep learning" and "fake," but the implications go far beyond simple fakery.

[screen 3]

Early photo manipulation required expertise in software like Photoshop. Creating convincing fake video was nearly impossible without Hollywood-level resources.

Today, free tools and apps can swap faces in videos, clone voices with minutes of audio samples, or generate photorealistic images of people who never existed.

[screen 4]

## How Deepfakes Work

Deepfakes use neural networks trained on thousands of images or hours of video. The AI learns patterns - how a person's face moves when they speak, their typical expressions, lighting conditions on their skin.

Once trained, the AI can generate new content: making someone appear to say things they never said, or creating entirely synthetic personas.

[screen 5]

### Types of Synthetic Media

**Face swap**: Replacing one person's face with another's in video

**Voice cloning**: Generating audio that sounds like a specific person

**Lip-sync manipulation**: Changing mouth movements to match different words

**Fully synthetic**: Creating images or videos of people who don't exist

Each type poses different risks and requires different detection approaches.

[screen 6]

## Detection Techniques

Current detection methods look for artifacts - imperfections that reveal AI generation:

• Unnatural blinking patterns or lack of blinking

• Lighting inconsistencies on faces

• Blurred boundaries around faces

• Audio-visual mismatches (words don't match mouth movements exactly)

• Unnatural head movements or breathing patterns

[screen 7]

However, detection is an arms race. As AI improves, artifacts become harder to spot. Some synthetic content is now indistinguishable from authentic footage, even to experts with specialized software.

The concerning truth: detection technology is always playing catch-up to generation technology.

[screen 8]

## Real-World Impact

Deepfakes have been used to:

• Create non-consensual intimate imagery (most common use)

• Impersonate executives for financial fraud

• Spread political disinformation

• Generate fake evidence in legal proceedings

• Harass and intimidate journalists and activists

The technology becomes more accessible and convincing every month.

[screen 9]

## The "Liar's Dividend"

Beyond creating fake content, deepfakes create a more insidious problem: authentic content can now be dismissed as fake.

Politicians caught on video doing something embarrassing can claim "deepfake!" This erosion of trust in all video evidence is called the "liar's dividend" - liars benefit from general uncertainty about what's real.

[screen 10]

## Societal Implications

When seeing is no longer believing, we face a crisis of epistemology - how do we know what's true?

Traditional verification methods (eyewitness accounts, video evidence, photographic documentation) become unreliable. We may need to rethink how we establish truth in legal, journalistic, and democratic contexts.

[screen 11]

## What You Can Do

While detection technology struggles, human judgment still matters:

• Be skeptical of sensational video content, especially involving public figures

• Check if reputable news sources verify the content

• Look for the original source - who first posted it and why?

• Remember that extraordinary claims require extraordinary evidence

• Before sharing, pause and verify

The best defense against deepfakes is a healthy skepticism and verification habit.

## Subscribe now &
Get the latest updates

Subscribe
